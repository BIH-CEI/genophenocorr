{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setup for visualizers**\n",
    "\n",
    "The notebook loads a cohort of patients with mutations in *PTPN11*, performs the functional variant annotation, and collates the data into a `Cohort` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import hpotk\n",
    "\n",
    "hpotk.util.setup_logging()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup resources\n",
    "\n",
    "Set up paths to resources that work on the system. \n",
    "\n",
    "We need just the path to the local copy of the *phenopacket-store* repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath_phenopacket_store = '/home/ielis/data/phenopacket-store'\n",
    "\n",
    "fpath_ptpn11 = os.path.join(fpath_phenopacket_store, 'notebooks', 'PTPN11', 'phenopackets')\n",
    "assert os.path.isdir(fpath_ptpn11), 'Update path to folder with PTPN11 phenopackets' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load HPO\n",
    "\n",
    "Use HPO release *2023-10-09*. The ontology is downloaded from the PURL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2023-10-09'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import hpotk\n",
    "\n",
    "fpath_hpo = 'https://github.com/obophenotype/human-phenotype-ontology/releases/download/v2023-10-09/hp.json'\n",
    "\n",
    "hpo = hpotk.load_minimal_ontology(fpath_hpo)\n",
    "hpo.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure patient creator\n",
    "\n",
    "Patient creator transforms phenopackets into `Patient`s - the internal representation of the sample data. \n",
    "\n",
    "The transformation includes checking that the phenotypic features -  the uses HPO to check all phenotypic features are annotated with current HPO terms "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup phenotypic feature validation\n",
    "\n",
    "We ensure that the phenotypic features of the subjects meet the following validation requirements:\n",
    "- the phenotypic features are represented using current (non-obsolete) HPO term IDs\n",
    "- all phenotypic features are descendants of *Phenotypic abnormality* branch of HPO\n",
    "- the terms do not violate the annotation propagation rule - subjects are not annotated by a term and its ancestor/descendant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hpotk.validate import ValidationRunner\n",
    "from hpotk.validate import ObsoleteTermIdsValidator, PhenotypicAbnormalityValidator, AnnotationPropagationValidator\n",
    "\n",
    "validation_runner = ValidationRunner(\n",
    "    validators=(\n",
    "        ObsoleteTermIdsValidator(hpo), \n",
    "        PhenotypicAbnormalityValidator(hpo), \n",
    "        AnnotationPropagationValidator(hpo)\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from genophenocorr.preprocessing import configure_caching_patient_creator\n",
    "\n",
    "patient_creator = configure_caching_patient_creator(hpo, validation_runner=validation_runner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load phenopackets\n",
    "\n",
    "Walk the directory, find all JSON files, load them into phenopackets, and transform the phenopackets to patients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Loaded 42 samples'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from phenopackets import Phenopacket\n",
    "from google.protobuf.json_format import Parse\n",
    "\n",
    "samples = []\n",
    "for dirpath, dirnames, filenames in os.walk(fpath_ptpn11):\n",
    "    for filename in filenames:\n",
    "        if filename.endswith('.json'):\n",
    "            fpath_pp = os.path.join(dirpath, filename)\n",
    "            pp = Phenopacket()\n",
    "            with open(fpath_pp) as fh:\n",
    "                Parse(fh.read(), pp)\n",
    "            patient = patient_creator.create_patient(pp)\n",
    "            samples.append(patient)\n",
    "\n",
    "f'Loaded {len(samples)} samples'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gather samples into cohort\n",
    "\n",
    "Gather the samples and calculate the cohort summary statistics such as transcripts affected by the variants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NM_001330437.2', 'NM_001374625.1', 'NM_002834.5', 'NM_080601.3'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from genophenocorr.model import Cohort\n",
    "\n",
    "cohort = Cohort.from_patients(samples)\n",
    "cohort.all_transcripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gather data for visualization\n",
    "\n",
    "Here we get the data required for visualizing the variants on selected transcript or protein."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose the transcript\n",
    "\n",
    "We need to choose the transcript and protein IDs - currently this is done manually but we will find a way how to do this automatically, e.g. using MANE transcript.\n",
    "\n",
    "The MANE transcript for *PTPN11* is [NM_002834.5](https://www.genenames.org/data/gene-symbol-report/#!/hgnc_id/HGNC:9644)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_id = 'NM_002834.5'\n",
    "protein_id = 'NP_002825.3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gather the data for visualization\n",
    "\n",
    "We need to get:\n",
    "- variants\n",
    "- transcript coordinates\n",
    "- protein metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variants\n",
    "\n",
    "Variants are easy, `Cohort` exposes all the variants via the `all_variants` property:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variants = cohort.all_variants\n",
    "len(variants)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transcript coordinates\n",
    "\n",
    "Transcript coordinates can be fetched from Variant Validator API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TranscriptCoordinates(identifier=NM_002834.5, region=GenomicRegion(contig=12, start=112418946, end=112509918, strand=+))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from genophenocorr.model.genome import GRCh38 \n",
    "from genophenocorr.preprocessing import VVTranscriptCoordinateService\n",
    "\n",
    "txc_service = VVTranscriptCoordinateService(genome_build=GRCh38)\n",
    "tx_coordinates = txc_service.fetch(tx_id)\n",
    "tx_coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `TranscriptCoordinates` object knows about the number of coding bases and aminoacid codons. \n",
    "\n",
    "Note, the counts of coding bases and codons do *not* include the termination codon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NM_002834.5 has 1,779 coding bases\n",
      "NM_002834.5 has 593 codons\n"
     ]
    }
   ],
   "source": [
    "print(f'{tx_id} has {tx_coordinates.compute_n_coding_bases():,} coding bases')\n",
    "print(f'{tx_id} has {tx_coordinates.compute_n_codons():,} codons')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Protein metadata\n",
    "\n",
    "Last, we fetch the protein metadata from Uniprot.\n",
    "\n",
    "The significance of the warning that is logged is unclear to me at this time. We need to investigate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-11 17:31:07,545 genophenocorr.preprocessing._uniprot WARNING : UniProt did not return a protein ID that matches the ID we searched for: NP_002825.3 not in ['NP_001308315.1', 'NP_001308316.1', 'NP_002816.1']\n",
      "2023-12-11 17:31:07,546 genophenocorr.preprocessing._uniprot WARNING : UniProt did not return a protein ID that matches the ID we searched for: NP_002825.3 not in ['NP_001172004.1', 'NP_001172005.1', 'NP_001172010.1', 'NP_001172011.1', 'NP_002015.1']\n",
      "2023-12-11 17:31:07,546 genophenocorr.preprocessing._uniprot WARNING : UniProt did not return a protein ID that matches the ID we searched for: NP_002825.3 not in ['NP_000508.1', 'NP_000549.1']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ProteinMetadata(id=NP_002825.3, label=Tyrosine-protein phosphatase non-receptor type 11, features=(SimpleProteinFeature(type=FeatureType.DOMAIN, info=FeatureInfo(name=SH2 1, start=6, end=102)), SimpleProteinFeature(type=FeatureType.DOMAIN, info=FeatureInfo(name=SH2 2, start=112, end=216)), SimpleProteinFeature(type=FeatureType.DOMAIN, info=FeatureInfo(name=Tyrosine-protein phosphatase, start=247, end=517)), SimpleProteinFeature(type=FeatureType.REGION, info=FeatureInfo(name=Disordered, start=548, end=571))))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from genophenocorr.preprocessing import UniprotProteinMetadataService\n",
    "\n",
    "pms = UniprotProteinMetadataService()\n",
    "\n",
    "protein_metas = pms.annotate(protein_id)\n",
    "\n",
    "assert len(protein_metas) == 1\n",
    "protein_meta = protein_metas[0]\n",
    "protein_meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get metadata with 4 features (3 domains and 1 region), which is in line with the Uniprot [Family & Domains section](https://www.uniprot.org/uniprotkb/Q06124/entry#family_and_domains)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleProteinFeature(type=FeatureType.DOMAIN, info=FeatureInfo(name=SH2 1, start=6, end=102))\n",
      "SimpleProteinFeature(type=FeatureType.DOMAIN, info=FeatureInfo(name=SH2 2, start=112, end=216))\n",
      "SimpleProteinFeature(type=FeatureType.DOMAIN, info=FeatureInfo(name=Tyrosine-protein phosphatase, start=247, end=517))\n",
      "SimpleProteinFeature(type=FeatureType.REGION, info=FeatureInfo(name=Disordered, start=548, end=571))\n"
     ]
    }
   ],
   "source": [
    "for feature in protein_meta.protein_features:\n",
    "    print(feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we *do not* get is the length of the protein sequence. In the worst case, we can calculate it from the CDS length."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Draw the figures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's draw the plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from genophenocorr.view import VariantTranscriptProteinArtist\n",
    "\n",
    "artist = VariantTranscriptProteinArtist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO - implement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist.draw_variants(variants, tx_coordinates, protein_meta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exploratory",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
