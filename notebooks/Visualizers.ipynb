{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setup for visualizers**\n",
    "\n",
    "The notebook loads a cohort of patients with mutations in *PTPN11*, performs the functional variant annotation, and collates the data into a `Cohort` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import hpotk\n",
    "\n",
    "hpotk.util.setup_logging()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup resources\n",
    "\n",
    "Set up paths to resources that work on the system. \n",
    "\n",
    "We need just the path to the local copy of the *phenopacket-store* repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath_phenopacket_store = '/home/ielis/data/phenopacket-store'\n",
    "\n",
    "fpath_ptpn11 = os.path.join(fpath_phenopacket_store, 'notebooks', 'PTPN11', 'phenopackets')\n",
    "assert os.path.isdir(fpath_ptpn11), 'Update path to folder with PTPN11 phenopackets' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load HPO\n",
    "\n",
    "Use HPO release *2023-10-09*. The ontology is downloaded from the PURL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2023-10-09'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import hpotk\n",
    "\n",
    "fpath_hpo = 'https://github.com/obophenotype/human-phenotype-ontology/releases/download/v2023-10-09/hp.json'\n",
    "\n",
    "hpo = hpotk.load_minimal_ontology(fpath_hpo)\n",
    "hpo.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure patient creator\n",
    "\n",
    "Patient creator transforms phenopackets into `Patient`s - the internal representation of the sample data. \n",
    "\n",
    "The transformation includes checking that the phenotypic features -  the uses HPO to check all phenotypic features are annotated with current HPO terms "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup phenotypic feature validation\n",
    "\n",
    "We ensure that the phenotypic features of the subjects meet the following validation requirements:\n",
    "- the phenotypic features are represented using current (non-obsolete) HPO term IDs\n",
    "- all phenotypic features are descendants of *Phenotypic abnormality* branch of HPO\n",
    "- the terms do not violate the annotation propagation rule - subjects are not annotated by a term and its ancestor/descendant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hpotk.validate import ValidationRunner\n",
    "from hpotk.validate import ObsoleteTermIdsValidator, PhenotypicAbnormalityValidator, AnnotationPropagationValidator\n",
    "\n",
    "validation_runner = ValidationRunner(\n",
    "    validators=(\n",
    "        ObsoleteTermIdsValidator(hpo), \n",
    "        PhenotypicAbnormalityValidator(hpo), \n",
    "        AnnotationPropagationValidator(hpo)\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from genophenocorr.preprocessing import configure_caching_patient_creator\n",
    "\n",
    "patient_creator = configure_caching_patient_creator(hpo, validation_runner=validation_runner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load phenopackets\n",
    "\n",
    "Walk the directory, find all JSON files, load them into phenopackets, and transform the phenopackets to patients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Loaded 42 samples'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from phenopackets import Phenopacket\n",
    "from google.protobuf.json_format import Parse\n",
    "\n",
    "samples = []\n",
    "for dirpath, dirnames, filenames in os.walk(fpath_ptpn11):\n",
    "    for filename in filenames:\n",
    "        if filename.endswith('.json'):\n",
    "            fpath_pp = os.path.join(dirpath, filename)\n",
    "            pp = Phenopacket()\n",
    "            with open(fpath_pp) as fh:\n",
    "                Parse(fh.read(), pp)\n",
    "            patient = patient_creator.create_patient(pp)\n",
    "            samples.append(patient)\n",
    "\n",
    "f'Loaded {len(samples)} samples'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gather samples into cohort\n",
    "\n",
    "Gather the samples and calculate the cohort summary statistics such as transcripts affected by the variants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NM_001330437.2', 'NM_001374625.1', 'NM_002834.5', 'NM_080601.3'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from genophenocorr.model import Cohort\n",
    "\n",
    "cohort = Cohort.from_patients(samples)\n",
    "cohort.all_transcripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gather data for visualization\n",
    "\n",
    "Here we get the data required for visualizing the variants on selected transcript or protein."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose the transcript\n",
    "\n",
    "We need to choose the transcript and protein IDs - currently this is done manually but we will find a way how to do this automatically, e.g. using MANE transcript.\n",
    "\n",
    "The MANE transcript for *PTPN11* is [NM_002834.5](https://www.genenames.org/data/gene-symbol-report/#!/hgnc_id/HGNC:9644)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_id = 'NM_002834.5'\n",
    "protein_id = 'NP_002825.3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gather the data for visualization\n",
    "\n",
    "We need to get:\n",
    "- variants\n",
    "- transcript coordinates\n",
    "- protein metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variants\n",
    "\n",
    "Variants are easy, `Cohort` exposes all the variants via the `all_variants` property:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variants = cohort.all_variants\n",
    "len(variants)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transcript coordinates\n",
    "\n",
    "Transcript coordinates can be fetched from Variant Validator API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "503 Server Error: Service Unavailable for url: https://rest.variantvalidator.org/VariantValidator/tools/gene2transcripts/NM_002834.5",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgenophenocorr\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VVTranscriptCoordinateService\n\u001b[1;32m      4\u001b[0m txc_service \u001b[38;5;241m=\u001b[39m VVTranscriptCoordinateService(genome_build\u001b[38;5;241m=\u001b[39mGRCh38)\n\u001b[0;32m----> 5\u001b[0m tx_coordinates \u001b[38;5;241m=\u001b[39m \u001b[43mtxc_service\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtx_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m tx_coordinates\n",
      "File \u001b[0;32m~/ielis/phenotypes/genophenocorr/src/genophenocorr/preprocessing/_vv.py:144\u001b[0m, in \u001b[0;36mVVTranscriptCoordinateService.fetch\u001b[0;34m(self, tx)\u001b[0m\n\u001b[1;32m    141\u001b[0m response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(api_url, headers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_headers, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout)\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m response\u001b[38;5;241m.\u001b[39mok:\n\u001b[0;32m--> 144\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_response(tx_id, response\u001b[38;5;241m.\u001b[39mjson())\n",
      "File \u001b[0;32m~/ielis/venvs/exploratory/lib/python3.10/site-packages/requests/models.py:1021\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1016\u001b[0m     http_error_msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1017\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Server Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreason\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for url: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1018\u001b[0m     )\n\u001b[1;32m   1020\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1021\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 503 Server Error: Service Unavailable for url: https://rest.variantvalidator.org/VariantValidator/tools/gene2transcripts/NM_002834.5"
     ]
    }
   ],
   "source": [
    "from genophenocorr.model.genome import GRCh38 \n",
    "from genophenocorr.preprocessing import VVTranscriptCoordinateService\n",
    "\n",
    "txc_service = VVTranscriptCoordinateService(genome_build=GRCh38)\n",
    "tx_coordinates = txc_service.fetch(tx_id)\n",
    "tx_coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `TranscriptCoordinates` object knows about the number of coding bases and aminoacid codons. \n",
    "\n",
    "Note, the counts of coding bases and codons do *not* include the termination codon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tx_coordinates' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtx_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mtx_coordinates\u001b[49m\u001b[38;5;241m.\u001b[39mget_coding_base_count()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m coding bases\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtx_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtx_coordinates\u001b[38;5;241m.\u001b[39mget_codon_count()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m codons\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tx_coordinates' is not defined"
     ]
    }
   ],
   "source": [
    "print(f'{tx_id} has {tx_coordinates.get_coding_base_count():,} coding bases')\n",
    "print(f'{tx_id} has {tx_coordinates.get_codon_count():,} codons')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get the UTR regions (both 5' and 3') as well as the CDS regions.\n",
    "\n",
    "Note, for simplicity, the CDS regions include *both* initiation and termination codons!\n",
    "\n",
    "5' UTR regions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for utr in tx_coordinates.get_five_prime_utrs():\n",
    "    print(f'{utr.start:,}-{utr.end:,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CDS regions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cds in tx_coordinates.get_cds_regions():\n",
    "    print(f'{cds.start:,}-{cds.end:,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3' UTR regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for utr in tx_coordinates.get_three_prime_utrs():\n",
    "    print(f'{utr.start:,}-{utr.end:,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Protein metadata\n",
    "\n",
    "Last, we fetch the protein metadata from Uniprot.\n",
    "\n",
    "The significance of the warning that is logged is unclear to me at this time. We need to investigate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from genophenocorr.preprocessing import UniprotProteinMetadataService\n",
    "\n",
    "pms = UniprotProteinMetadataService()\n",
    "\n",
    "protein_metas = pms.annotate(protein_id)\n",
    "\n",
    "assert len(protein_metas) == 1\n",
    "protein_meta = protein_metas[0]\n",
    "protein_meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get metadata with 4 features (3 domains and 1 region), which is in line with the Uniprot [Family & Domains section](https://www.uniprot.org/uniprotkb/Q06124/entry#family_and_domains)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in protein_meta.protein_features:\n",
    "    print(feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we *do not* get is the length of the protein sequence. In the worst case, we can calculate it from the CDS length."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Draw the figures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's draw the plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from genophenocorr.view import VariantTranscriptProteinArtist\n",
    "\n",
    "artist = VariantTranscriptProteinArtist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO - implement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist.draw_variants(variants, tx_coordinates, protein_meta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exploratory",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
